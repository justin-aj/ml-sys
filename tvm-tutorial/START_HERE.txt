=================================================================
    TVM (Tensor Virtual Machine) - Getting Started Guide
=================================================================

Welcome! This tutorial teaches you TVM, an open-source deep learning compiler.

WHAT IS TVM?
------------
TVM is a compiler that:
- Takes high-level deep learning models (PyTorch, TensorFlow, ONNX)
- Optimizes them for ANY hardware (GPU, CPU, mobile, custom accelerators)
- Auto-tunes performance to beat hand-written kernels
- Generates highly optimized machine code

Think: "LLVM for deep learning" - write once, optimize everywhere.


WHY LEARN TVM?
--------------
✓ Deploy models on ANY hardware (NVIDIA GPU, AMD GPU, ARM, x86, TPU, etc.)
✓ Automatically optimize kernels (often faster than cuDNN/cuBLAS!)
✓ Understand how ML compilers work under the hood
✓ Used in production: AWS, Meta, AMD, NVIDIA, OctoML


YOUR LEARNING PATH
------------------
1. START HERE.txt ← You are here
2. simple_intro.py - PyTorch vs TVM comparison (no GPU needed)
3. gpu_optimization.py - GPU kernel optimization on your V100
4. auto_tuning.py - Let TVM auto-tune for peak performance
5. LEARNING_GUIDE.md - Deep dive into TVM concepts
6. REAL_WORLD_USES.md - Production use cases


QUICK START (5 minutes)
-----------------------
Step 1: Install TVM
    pip install -r requirements.txt

Step 2: Run the intro example
    python simple_intro.py

Step 3: Run GPU optimization (if you have CUDA)
    python gpu_optimization.py

Step 4: Try auto-tuning (this takes longer, ~10-30 min)
    python auto_tuning.py


WHAT YOU'LL LEARN
-----------------
✓ How to compile PyTorch models with TVM
✓ Schedule optimization (tiling, vectorization, parallelization)
✓ GPU optimization (thread binding, shared memory, tensor cores)
✓ Auto-tuning with AutoScheduler/MetaSchedule
✓ Cross-compilation for different hardware
✓ How TVM compares to CUDA, Triton, XLA


YOUR GPU
--------
You have: Tesla V100-SXM2-32GB
- Perfect for this tutorial!
- TVM will optimize kernels specifically for Volta architecture
- Expect speedups over PyTorch eager mode


PREREQUISITES
-------------
✓ Basic Python knowledge
✓ Understanding of neural network operations (matmul, conv, etc.)
✓ CUDA GPU (optional but recommended - CPU works too!)
✓ Patience (auto-tuning can take time, but it's worth it!)


NEXT STEPS
----------
1. Install dependencies: pip install -r requirements.txt
2. Read LEARNING_GUIDE.md for concepts
3. Run simple_intro.py to see TVM in action
4. Experiment and have fun!


GETTING HELP
------------
- Official docs: https://tvm.apache.org/docs/
- Discuss forum: https://discuss.tvm.apache.org/
- GitHub: https://github.com/apache/tvm
- Tutorial collection: https://tvm.apache.org/docs/tutorial/


Let's get started! Run: python simple_intro.py
=================================================================
