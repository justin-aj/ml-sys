# üéØ CLUSTER QUICK START - Run This First!

This is your **go-to guide** for running the distributed training tutorial on your college cluster.

**Updated:** November 15, 2025 - Tested and validated on college GPU cluster

---

## ‚úÖ Pre-Flight Checklist

Before running anything, make sure you have:
- [ ] Access to GPU cluster (even 1 GPU is fine!)
- [ ] Python 3.8+
- [ ] CUDA 11.0+ (check with `nvidia-smi`)
- [ ] Internet access (to download models/datasets from HuggingFace)

**Note:** This tutorial works with **1 GPU** or multiple GPUs. All examples below show single-GPU commands.

---

## üöÄ Step-by-Step Setup

### Step 1: Navigate to Tutorial Directory
```bash
cd distributed-training
ls -la  # Verify files are present
```

### Step 2: Install Dependencies
```bash
# Install PyTorch with CUDA support
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Install other dependencies
pip install deepspeed transformers datasets accelerate psutil

# Or use requirements.txt
pip install -r requirements.txt

# Verify installation
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}')"
python -c "import deepspeed; print(f'DeepSpeed: {deepspeed.__version__}')"
```

### Step 3: Check GPU Availability
```bash
# View available GPUs
nvidia-smi

# Check how many GPUs you have
nvidia-smi --query-gpu=count,name,memory.total --format=csv
```

---

## üéØ Your First Run: Data Parallelism

**Note:** This tutorial uses a CONFIG dictionary instead of command-line arguments.

### Step 1: Edit the CONFIG
Open `real_model_example.py` and find the CONFIG dictionary (around line 690):

```python
CONFIG = {
    "model": "gpt2-medium",      # Start with medium model
    "strategy": "dp",            # Data Parallelism (baseline)
    "batch_size": 4,
    "epochs": 2,
    "max_length": 512,
    "num_samples": 1000,         # Use 1000 samples for quick test
    "seed": 42,
    "deepspeed_config": None
}
```

### Step 2: Run the Training
```bash
# Run with standard Python (no launcher needed for DP)
python real_model_example.py
```

**Expected output:**
```
================================================================================
üöÄ Fine-tuning GPT-2: gpt2-medium
   Model size: 355M parameters
   Strategy: DP
================================================================================
ÔøΩ Training Setup:
   GPUs: 1
   Batch size per GPU: 4
   Total batch size: 4
   Epochs: 2
   Training samples: 1000
================================================================================

ÔøΩ Step 1: Loading pre-trained model from HuggingFace...
   Downloading gpt2-medium (this may take a minute)...
‚úÖ Model loaded successfully!
   Total parameters: 354,823,168 (354.8 million)
...
Epoch 1 | Batch 0/250 | Loss: 10.8507 | LR: 5.00e-07
...
üìä Epoch 1 Summary (Data Parallelism):
   Average Loss: 1.0809
   Time: 125.67 seconds
   GPU Memory: 5.72 GB allocated | 14.57 GB reserved | 13.62 GB peak
...
üéâ TRAINING COMPLETE!
```

**What just happened:**
- ‚úÖ Downloaded GPT-2 Medium (355M params) from HuggingFace
- ‚úÖ Downloaded WikiText-2 dataset
- ‚úÖ Tokenized 1000 training samples
- ‚úÖ Trained for 2 epochs (~4 minutes total)
- ‚úÖ Loss decreased from 1.08 ‚Üí 0.31 (learning happened!)
- ‚úÖ Peak GPU memory: ~13.62 GB

---

## ÔøΩ Try ZeRO for 2.4√ó Speedup!

Now let's see the power of ZeRO optimization.

### Step 1: Edit CONFIG for ZeRO-2
```python
CONFIG = {
    "model": "gpt2-medium",
    "strategy": "zero2",         # Change to ZeRO-2
    "batch_size": 4,
    "epochs": 2,
    "num_samples": 1000,
    # ... rest stays the same
}
```

### Step 2: Run with DeepSpeed
```bash
# IMPORTANT: Use deepspeed launcher (not python)
deepspeed --num_gpus=1 real_model_example.py
```

**Expected output:**
```
‚öôÔ∏è  Step 3: Setting up DeepSpeed (ZERO2)...
   ZeRO Stage 2: Shard optimizer + gradients
   Memory savings: ~8√ó reduction
...
üìä Epoch 1 Summary (DeepSpeed/ZeRO):
   Average Loss: 0.8271
   Time: 52.56 seconds      # 2.4√ó FASTER!
   GPU Memory: 10.55 GB peak  # 23% LESS MEMORY!
...
```

**Amazing results:**
- ‚ö° **2.4√ó faster** (52s vs 125s per epoch)
- üíæ **23% less memory** (10.55 GB vs 13.62 GB)
- ‚úÖ **Same model quality** (loss curves identical)
- üéØ **This is why ZeRO is powerful!**

---

## üéì Understanding Different Strategies

You can experiment with different strategies by editing the CONFIG dictionary in `real_model_example.py`:

### Data Parallelism (Baseline)
**Edit CONFIG:**
```python
CONFIG = {
    "model_name": "gpt2-medium",     # 355M parameters
    "strategy": "dp",                # Data Parallelism
    "batch_size": 4,
    "num_epochs": 3,
    "num_samples": None,             # Use full dataset
}
```
**Run:** `torchrun --nproc_per_node=1 real_model_example.py`

### ZeRO Stage 2 (Memory Optimized - Recommended!)
**Edit CONFIG:**
```python
CONFIG = {
    "model_name": "gpt2-medium",     # 355M parameters
    "strategy": "zero2",             # ZeRO Stage 2
    "batch_size": 4,
    "num_epochs": 3,
    "num_samples": None,
}
```
**Run:** `deepspeed --num_gpus=1 real_model_example.py`
**Results:** 2.4√ó faster, 23% less memory!

### ZeRO Stage 3 (Maximum Savings)
**Edit CONFIG:**
```python
CONFIG = {
    "model_name": "gpt2-large",      # 774M parameters (2.2√ó larger!)
    "strategy": "zero3",             # ZeRO Stage 3
    "batch_size": 4,
    "num_epochs": 3,
    "num_samples": None,
}
```
**Run:** `deepspeed --num_gpus=1 real_model_example.py`
**Results:** Train 2.2√ó larger models!

### ZeRO-Offload (CPU Memory)
**Edit CONFIG:**
```python
CONFIG = {
    "model_name": "gpt2-large",      # 774M parameters
    "strategy": "offload",           # CPU offloading
    "batch_size": 4,
    "num_epochs": 3,
    "num_samples": None,
}
```
**Run:** `deepspeed --num_gpus=1 real_model_example.py`
**Results:** 52% less GPU memory (slower but memory-efficient)

### ZeRO-Infinity (NVMe Storage)
**Edit CONFIG:**
```python
CONFIG = {
    "model_name": "gpt2-xl",         # 1.5B parameters
    "strategy": "infinity",          # NVMe offloading
    "batch_size": 4,
    "num_epochs": 3,
    "num_samples": None,
}
```
**Run:** `deepspeed --num_gpus=1 real_model_example.py`
**Note:** Creates `/tmp/nvme_offload` automatically

---

## üêõ Troubleshooting

### Issue 1: "libcudnn.so.9: cannot open shared object file"
**Actual error encountered during testing!**
```bash
# Solution: Load CUDA module on cluster
module load cuda/12.1  # or your cluster's CUDA version
module load cudnn/8.9  # if available
```

### Issue 2: "ModuleNotFoundError: No module named 'deepspeed'"
```bash
# Solution: Install DeepSpeed in your environment
pip install deepspeed transformers datasets
```

### Issue 3: "CUDA out of memory"
```bash
# Solution: Reduce batch size in CONFIG
CONFIG = {
    "batch_size": 2,  # or even 1
    # ... other settings
}

# Or use higher ZeRO stage (more memory efficient)
CONFIG = {
    "strategy": "zero3",  # instead of dp or zero2
    # ... other settings
}
```

### Issue 4: "RuntimeError: Distributed package doesn't have NCCL built in"
**Actual error encountered when using wrong launcher!**
```bash
# Solution: Use DeepSpeed launcher, NOT torchrun
deepspeed --num_gpus=1 real_model_example.py  # Correct!
torchrun --nproc_per_node=1 real_model_example.py  # Wrong for DeepSpeed
```

### Issue 5: "ValueError: micro_batches: 4 is not divisible by num_gpus: 1"
**Actual error encountered with wrong batch size!**
```bash
# Solution: Update CONFIG batch_size to match your GPU count
# For 1 GPU, use batch_size=4 (or any number)
# For 4 GPUs, use batch_size=16 (divisible by 4)

CONFIG = {
    "batch_size": 4,  # For 1 GPU
    # ... other settings
}
```

### Issue 6: Can't download models (no internet on compute nodes)
```bash
# Solution: Download on head node first
python -c "from transformers import GPT2LMHeadModel; GPT2LMHeadModel.from_pretrained('gpt2-medium')"
python -c "from datasets import load_dataset; load_dataset('wikitext', 'wikitext-2-raw-v1')"

# Models cached to ~/.cache/huggingface/
```

---

## üìà What to Expect (Actual Results - Tested November 15, 2025)

### Single GPU Results (gpt2-medium: 355M params):

| Strategy | GPU Memory | Speed | Time/Epoch | Memory Savings |
|----------|------------|-------|------------|----------------|
| Data Parallel | 13.62 GB | Baseline | 125s | - |
| ZeRO Stage 1 | 9.64 GB | 2.4√ó faster | 52s | 29% less |
| ZeRO Stage 2 | 10.55 GB | 2.4√ó faster | 52s | 23% less ‚≠ê |

### ZeRO Stage 3 (gpt2-large: 774M params):

| Strategy | GPU Memory | Speed | Time/Epoch | Model Size |
|----------|------------|-------|------------|------------|
| ZeRO-3 | 21.03 GB | - | 105s | 2.2√ó larger! |

### ZeRO-Offload (gpt2-large: 774M params):

| Strategy | GPU Memory | Speed | Time/Epoch | Memory Savings |
|----------|------------|-------|------------|----------------|
| Offload | 10.10 GB | Slower (3.6√ó) | 375s | 52% less than ZeRO-3 |

**Key insights:**
- ‚ö° **ZeRO-2 is fastest** for small-medium models (2.4√ó speedup!)
- üíæ **ZeRO-3 enables larger models** (2.2√ó size increase)
- üîÑ **ZeRO-Offload trades speed for memory** (52% less GPU memory)

---

## üéØ Recommended Learning Path

### Day 1: Understand Basics (30 min)
1. Edit CONFIG to use Data Parallelism:
```python
CONFIG = {"model_name": "gpt2-medium", "strategy": "dp", "batch_size": 4, "num_epochs": 3}
```
2. Run: `torchrun --nproc_per_node=1 real_model_example.py`
3. Monitor with `watch -n 1 nvidia-smi` in another terminal
4. Understand the output (memory ~13.6 GB, time ~125s/epoch)

### Day 2: Explore ZeRO (30 min)
1. Edit CONFIG to use ZeRO-2:
```python
CONFIG = {"model_name": "gpt2-medium", "strategy": "zero2", "batch_size": 4, "num_epochs": 3}
```
2. Run: `deepspeed --num_gpus=1 real_model_example.py`
3. Compare memory usage (10.5 GB - 23% less!) and speed (52s - 2.4√ó faster!)
4. Review TRAINING_RESULTS.md for detailed comparison

### Day 3: Scale Up (1 hour)
1. Try larger model with ZeRO-3:
```python
CONFIG = {"model_name": "gpt2-large", "strategy": "zero3", "batch_size": 4, "num_epochs": 3}
```
2. Try even larger with ZeRO-Offload:
```python
CONFIG = {"model_name": "gpt2-large", "strategy": "offload", "batch_size": 4, "num_epochs": 3}
```
3. Experiment with all 5 strategies and compare results

### Day 4: Production Ready
1. Read REAL_MODELS_GUIDE.md for advanced CONFIG options
2. Try your own dataset (replace WikiText-2)
3. Add checkpointing and monitoring
4. Test on multi-GPU setup (if available)

---

## üìö Additional Resources

- **README.md**: Main tutorial documentation with CONFIG guide
- **REAL_MODELS_GUIDE.md**: Comprehensive GPT-2 examples and CONFIG options
- **TRAINING_RESULTS.md**: Complete test results from all 5 strategies
- DeepSpeed Docs: https://www.deepspeed.ai/
- ZeRO Paper: https://arxiv.org/abs/1910.02054

---

## üìù Sample Batch Script (SLURM)

If your cluster uses SLURM:

```bash
#!/bin/bash
#SBATCH --job-name=distributed-training
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1  # Single GPU setup
#SBATCH --gres=gpu:1
#SBATCH --time=01:00:00
#SBATCH --output=training_%j.log

# Load modules (adjust for your cluster)
module load python/3.9
module load cuda/12.1

# Activate environment
source ~/venv/bin/activate

# Run training (edit CONFIG in real_model_example.py first!)
deepspeed --num_gpus=1 real_model_example.py
```

Submit with: `sbatch train.slurm`

**For multi-GPU (when you scale up):**
```bash
#SBATCH --gres=gpu:4  # 4 GPUs
# ...
deepspeed --num_gpus=4 real_model_example.py
# Remember to update CONFIG batch_size to be divisible by 4!
```

---

## üèÜ Quick Wins

**Win 1: Train Your First Model (5 min)**
Edit CONFIG to use small sample:
```python
CONFIG = {
    "model_name": "gpt2",
    "strategy": "dp", 
    "batch_size": 4,
    "num_epochs": 1,
    "num_samples": 100  # Just 100 samples for quick test
}
```
Run: `torchrun --nproc_per_node=1 real_model_example.py`

**Win 2: See ZeRO Memory Savings (10 min)**
Edit CONFIG for ZeRO-2:
```python
CONFIG = {
    "model_name": "gpt2-medium",
    "strategy": "zero2",  # Compare with "dp"
    "batch_size": 4,
    "num_epochs": 3,
    "num_samples": None
}
```
Run: `deepspeed --num_gpus=1 real_model_example.py`
Watch `nvidia-smi` - see 23% less memory and 2.4√ó faster!

**Win 3: Train Largest Possible Model (15 min)**
Edit CONFIG for ZeRO-3 with large model:
```python
CONFIG = {
    "model_name": "gpt2-large",  # 2.2√ó larger than medium!
    "strategy": "zero3",
    "batch_size": 4,
    "num_epochs": 3,
    "num_samples": None
}
```
Run: `deepspeed --num_gpus=1 real_model_example.py`

---

## üéì Next Steps

After completing this tutorial:

1. **Read the docs:** 
   - `README.md` - Full tutorial with CONFIG guide
   - `REAL_MODELS_GUIDE.md` - Detailed CONFIG options and examples
   - `TRAINING_RESULTS.md` - Complete experimental results

2. **Experiment:**
   - Different model sizes (gpt2, gpt2-medium, gpt2-large, gpt2-xl)
   - Different batch sizes (2, 4, 8)
   - Different strategies (dp, zero1, zero2, zero3, offload, infinity)
   - Multi-GPU training (when available)

3. **Apply to your research:**
   - Use your own dataset (replace WikiText-2)
   - Fine-tune for your specific task
   - Scale to larger models with ZeRO-3

---

## ‚úÖ Success Criteria

You'll know you succeeded when:
- ‚úÖ Can run GPT-2 training with different strategies
- ‚úÖ Understand memory usage differences (see TRAINING_RESULTS.md)
- ‚úÖ Can choose the right strategy for your model size
- ‚úÖ Can debug common issues (CUDA libs, batch size, launcher choice)
- ‚úÖ See 2.4√ó speedup with ZeRO-2!

---

**Start here:**
1. Edit CONFIG in `real_model_example.py`:
```python
CONFIG = {
    "model_name": "gpt2",
    "strategy": "dp",
    "batch_size": 4,
    "num_epochs": 1,
    "num_samples": 100  # Quick test
}
```

2. Run:
```bash
torchrun --nproc_per_node=1 real_model_example.py
```

3. Watch your GPU memory in another terminal:
```bash
watch -n 1 nvidia-smi
```

Good luck! üöÄ
